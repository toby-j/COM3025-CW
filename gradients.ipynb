{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgNdhpLOvFjm"
   },
   "source": [
    "# Imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "qDkEGwmWu8Bx",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.557340100Z",
     "start_time": "2023-05-12T17:32:45.617475300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from keras import Sequential\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7A6B6RebmmE"
   },
   "source": [
    "\n",
    "# Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7jxu5s9dbp9P",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.572170500Z",
     "start_time": "2023-05-12T17:32:50.560340Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def output_metrics(model, X_test, y_test):\n",
    "    # Use the trained model to make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f'F1 score: {f1:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fGgdn5RUfZ-V",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.615467500Z",
     "start_time": "2023-05-12T17:32:50.574174600Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_and_resize_image(image_path, size):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, size)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def ShowGrayscaleImage(im, title='', ax=None):\n",
    "  if ax is None:\n",
    "    P.figure()\n",
    "  P.axis('off')\n",
    "\n",
    "  P.imshow(im, cmap=P.cm.gray, vmin=0, vmax=1)\n",
    "  P.title(title)"
   ],
   "metadata": {
    "id": "10o0c6Nxwvdn",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.615467500Z",
     "start_time": "2023-05-12T17:32:50.591469600Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "transformer = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "def PreprocessImages(images):\n",
    "    # assumes input is 4-D, with range [0,255]\n",
    "    #\n",
    "    # torchvision have color channel as first dimension\n",
    "    # with normalization relative to mean/std of ImageNet:\n",
    "    #    https://pytorch.org/vision/stable/models.html\n",
    "    images = np.array(images)\n",
    "    images = images/255\n",
    "    images = np.transpose(images, (0,3,1,2))\n",
    "    images = torch.tensor(images, dtype=torch.float32)\n",
    "    images = transformer.forward(images)\n",
    "    return images.requires_grad_(True)"
   ],
   "metadata": {
    "id": "1Eifbs32w2CP",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.629020400Z",
     "start_time": "2023-05-12T17:32:50.605917600Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def normaliseGradients(image_3d, percentile=99):\n",
    "    image_2d = np.sum(np.abs(image_3d), axis=2)\n",
    "\n",
    "    # Get max pixel value in the image\n",
    "    vmax = np.percentile(image_2d, percentile)\n",
    "    # Get minimum pixel value in the image\n",
    "    vmin = np.min(image_2d)\n",
    "\n",
    "    # Normalise the values. We clip intensities so values lower than 0 are equal 0.\n",
    "    return np.clip((image_2d - vmin) / (vmax - vmin), 0, 1)"
   ],
   "metadata": {
    "id": "bH5P4ljFw-GB",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.636568700Z",
     "start_time": "2023-05-12T17:32:50.622986200Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def visualiseImageToHeatmap(image_3d, percentile=99):\n",
    "    r\"\"\"Returns a 3D tensor as RGB 3D heatmap\n",
    "    Pixels with higher weightage in sailiency heatmap will most saturated and will correspond to high RGB values in output heatmap_rgb\n",
    "  \"\"\"\n",
    "    image_2d = normaliseGradients(image_3d)\n",
    "    # Create heatmap using \"jet\" colormap, which returns an RGBA image\n",
    "    heatmap = plt.get_cmap('jet')(image_2d) * 255\n",
    "\n",
    "    # Normalise to 0,255 so it's visible when pasted\n",
    "    return Image.fromarray(heatmap.astype(np.uint8), mode='RGBA'), image_2d"
   ],
   "metadata": {
    "id": "YXpx3NuHxHU7",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.672057900Z",
     "start_time": "2023-05-12T17:32:50.638570Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def LoadImage(file_path):\n",
    "    im = PIL.Image.open(file_path)\n",
    "    im = im.resize((299, 299))\n",
    "    im = np.asarray(im)\n",
    "    return im"
   ],
   "metadata": {
    "id": "YnWSL8qMxaaY",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.672057900Z",
     "start_time": "2023-05-12T17:32:50.654274500Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def ShowImage(im, title='', ax=None):\n",
    "    if ax is None:\n",
    "        P.figure()\n",
    "    P.axis('off')\n",
    "    P.imshow(im)\n",
    "    P.title(title)"
   ],
   "metadata": {
    "id": "s-IRBHwxxkd2",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.690249900Z",
     "start_time": "2023-05-12T17:32:50.668468500Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def plot_confusion_matrix(model_input, test_data, test_labels):\n",
    "  predictions = model_input.predict(test_data)\n",
    "\n",
    "  y_pred  = np.argmax(predictions, axis=-1)\n",
    "  y_test = np.argmax(test_labels, axis=-1)\n",
    "\n",
    "  confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "  labels = list(set(y_test) | set(y_pred))\n",
    "  cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=labels)\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(10, 8))\n",
    "  cm_display.plot(ax=ax)\n",
    "\n",
    "\n",
    "  plt.show()"
   ],
   "metadata": {
    "id": "tKUKGubmyIi2",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.715101200Z",
     "start_time": "2023-05-12T17:32:50.685686400Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rwaor_SUveCb"
   },
   "source": [
    "# Kaggle dataset loading\n",
    " https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Qp8DNrdxvi97",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.715101200Z",
     "start_time": "2023-05-12T17:32:50.699215200Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -q kaggle\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPMG8P67vzfg"
   },
   "source": [
    "Upload your kaggle .json api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "YUok6YaGvyN6",
    "outputId": "38e95205-7c53-4922-9d8f-335253cf6e2a",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.732616200Z",
     "start_time": "2023-05-12T17:32:50.714099100Z"
    }
   },
   "outputs": [],
   "source": [
    "# files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xN85sd_Fv8qr",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.779145200Z",
     "start_time": "2023-05-12T17:32:50.730244400Z"
    }
   },
   "outputs": [],
   "source": [
    "# !mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4HD3RcoPv_XQ",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.779145200Z",
     "start_time": "2023-05-12T17:32:50.747340Z"
    }
   },
   "outputs": [],
   "source": [
    "# !cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "XTKF1IrbwChl",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.779145200Z",
     "start_time": "2023-05-12T17:32:50.760466Z"
    }
   },
   "outputs": [],
   "source": [
    "# !chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tatARidBwH20",
    "outputId": "d5058a53-4b60-4326-9ec6-cfb3628f3b1a",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.791256800Z",
     "start_time": "2023-05-12T17:32:50.776081700Z"
    }
   },
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d kmader/skin-cancer-mnist-ham10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IEfjefMTwQUX",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.824766Z",
     "start_time": "2023-05-12T17:32:50.792262800Z"
    }
   },
   "outputs": [],
   "source": [
    "# !unzip -q skin-cancer-mnist-ham10000.zip -d content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "02a5I2pIw9Gp",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.824766Z",
     "start_time": "2023-05-12T17:32:50.807642900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing the zip to save space\n",
    "# !rm skin-cancer-mnist-ham10000.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ek5Dfin9Svmd"
   },
   "source": [
    "## Dataset cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "GEzN-8pAu8Bz",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.868165300Z",
     "start_time": "2023-05-12T17:32:50.822767500Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('content/HAM10000_metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEjXq64_u8B2",
    "outputId": "d9038209-1746-498d-ed32-4dd800ecf693",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.881488300Z",
     "start_time": "2023-05-12T17:32:50.853610600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lesion_id      image_id     dx dx_type   age     sex localization   \n",
      "0      HAM_0000118  ISIC_0027419    bkl   histo  80.0    male        scalp  \\\n",
      "1      HAM_0000118  ISIC_0025030    bkl   histo  80.0    male        scalp   \n",
      "2      HAM_0002730  ISIC_0026769    bkl   histo  80.0    male        scalp   \n",
      "3      HAM_0002730  ISIC_0025661    bkl   histo  80.0    male        scalp   \n",
      "4      HAM_0001466  ISIC_0031633    bkl   histo  75.0    male          ear   \n",
      "...            ...           ...    ...     ...   ...     ...          ...   \n",
      "10010  HAM_0002867  ISIC_0033084  akiec   histo  40.0    male      abdomen   \n",
      "10011  HAM_0002867  ISIC_0033550  akiec   histo  40.0    male      abdomen   \n",
      "10012  HAM_0002867  ISIC_0033536  akiec   histo  40.0    male      abdomen   \n",
      "10013  HAM_0000239  ISIC_0032854  akiec   histo  80.0    male         face   \n",
      "10014  HAM_0003521  ISIC_0032258    mel   histo  70.0  female         back   \n",
      "\n",
      "            dataset  \n",
      "0      vidir_modern  \n",
      "1      vidir_modern  \n",
      "2      vidir_modern  \n",
      "3      vidir_modern  \n",
      "4      vidir_modern  \n",
      "...             ...  \n",
      "10010  vidir_modern  \n",
      "10011  vidir_modern  \n",
      "10012  vidir_modern  \n",
      "10013  vidir_modern  \n",
      "10014  vidir_modern  \n",
      "\n",
      "[10015 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0WUXP5JIu8B6",
    "outputId": "109e22ef-c37c-47bc-e888-05873a045a41",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.959454100Z",
     "start_time": "2023-05-12T17:32:50.871441500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     lesion_id      image_id   dx dx_type   age   sex localization   \n0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp  \\\n1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n\n        dataset  \n0  vidir_modern  \n1  vidir_modern  \n2  vidir_modern  \n3  vidir_modern  \n4  vidir_modern  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lesion_id</th>\n      <th>image_id</th>\n      <th>dx</th>\n      <th>dx_type</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>localization</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HAM_0000118</td>\n      <td>ISIC_0027419</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n      <td>vidir_modern</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HAM_0000118</td>\n      <td>ISIC_0025030</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n      <td>vidir_modern</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HAM_0002730</td>\n      <td>ISIC_0026769</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n      <td>vidir_modern</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HAM_0002730</td>\n      <td>ISIC_0025661</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n      <td>vidir_modern</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HAM_0001466</td>\n      <td>ISIC_0031633</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>75.0</td>\n      <td>male</td>\n      <td>ear</td>\n      <td>vidir_modern</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "41stH92zu8B-",
    "outputId": "0bdefcbd-0b66-4268-972f-6708465ab91c",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:50.974489200Z",
     "start_time": "2023-05-12T17:32:50.901502700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               age\ncount  9958.000000\nmean     51.863828\nstd      16.968614\nmin       0.000000\n25%      40.000000\n50%      50.000000\n75%      65.000000\nmax      85.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>9958.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>51.863828</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>16.968614</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>50.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>65.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>85.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "U6CC22ABu8CB",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:51.006535300Z",
     "start_time": "2023-05-12T17:32:50.916726800Z"
    }
   },
   "outputs": [],
   "source": [
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Bening keratosis-like lesions',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "ds_dir = 'content/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2-i_Kyq9u8CC",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:51.132535Z",
     "start_time": "2023-05-12T17:32:50.932387300Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "## Let's map the image_id with it's image path from part 1 and part 2 folders\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join(ds_dir, '*', '*.jpg'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Ge6Zi_Plu8CK",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:51.148124400Z",
     "start_time": "2023-05-12T17:32:51.042595100Z"
    }
   },
   "outputs": [],
   "source": [
    "df['path'] = df['image_id'].map(imageid_path_dict.get)\n",
    "df['cell_type'] = df['dx'].map(lesion_type_dict.get)\n",
    "df['cell_type_idx'] = pd.Categorical(df['cell_type']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0WLC4Dnu8CT",
    "outputId": "a4172b60-3976-445b-e697-758aa73cb0d3",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:51.149083700Z",
     "start_time": "2023-05-12T17:32:51.065539200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "lesion_id         0\nimage_id          0\ndx                0\ndx_type           0\nage              57\nsex               0\nlocalization      0\ndataset           0\npath              0\ncell_type         0\ncell_type_idx     0\ndtype: int64"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "id": "sGRsJl19L6El"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Tc5GD9g_u8Ci",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:32:51.174742300Z",
     "start_time": "2023-05-12T17:32:51.073900600Z"
    }
   },
   "outputs": [],
   "source": [
    "image_size = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ZYKNlFMbu8Cj",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:34:00.688214800Z",
     "start_time": "2023-05-12T17:32:51.096215Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the function to each image path in the 'path' column of the dataframe\n",
    "df['image'] = df['path'].apply(lambda x: read_and_resize_image(x, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEY2wp4Pu8Cj",
    "outputId": "ecb65a3d-0150-4357-c7c1-2355c5ae0ea3",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:34:00.705052600Z",
     "start_time": "2023-05-12T17:34:00.690218700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "image\n(64, 64, 3)    10015\nName: count, dtype: int64"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image'].map(lambda x: x.shape).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Ook1wZ-8u8Ck",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:34:00.760388Z",
     "start_time": "2023-05-12T17:34:00.706053300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "# We use stratify which splits the dataset with the same class inbalance as the dataset.\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['cell_type_idx'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "zYXLJyzGu8Ck",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:34:00.841276800Z",
     "start_time": "2023-05-12T17:34:00.738018700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the image data and target labels for train and test sets\n",
    "# TODO: We're only using images and cell_type_idx, we can experiment with adding more input data\n",
    "X_train = np.stack(train_df['image'].values)\n",
    "y_train = train_df['cell_type_idx'].values\n",
    "X_test = np.stack(test_df['image'].values)\n",
    "y_test = test_df['cell_type_idx'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Zrc8O6bxu8Cl",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:34:00.992872100Z",
     "start_time": "2023-05-12T17:34:00.844272100Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[1], image_size[0], 3)))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(df['cell_type_idx'].unique()), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "5rh1VsV6u8Cl",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:34:01.013917400Z",
     "start_time": "2023-05-12T17:34:00.985366500Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "6sF22aPZu8Cm",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f10bdd2a-95b3-4fb4-f27d-6e2d1d50f784",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:36:08.952221700Z",
     "start_time": "2023-05-12T17:34:01.014891200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 12s 727ms/step - loss: 62.8789 - accuracy: 0.4086 - val_loss: 1.7333 - val_accuracy: 0.1643\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 11s 724ms/step - loss: 1.4250 - accuracy: 0.5622 - val_loss: 1.0946 - val_accuracy: 0.6638\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 12s 764ms/step - loss: 1.1983 - accuracy: 0.6350 - val_loss: 1.1382 - val_accuracy: 0.6623\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 13s 833ms/step - loss: 1.1510 - accuracy: 0.6425 - val_loss: 1.0117 - val_accuracy: 0.6655\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 13s 843ms/step - loss: 1.0726 - accuracy: 0.6570 - val_loss: 0.9815 - val_accuracy: 0.6658\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 14s 893ms/step - loss: 1.0190 - accuracy: 0.6665 - val_loss: 0.9714 - val_accuracy: 0.6660\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 14s 861ms/step - loss: 1.0033 - accuracy: 0.6677 - val_loss: 0.9664 - val_accuracy: 0.6655\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 13s 810ms/step - loss: 0.9969 - accuracy: 0.6653 - val_loss: 0.9672 - val_accuracy: 0.6658\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 13s 799ms/step - loss: 0.9680 - accuracy: 0.6737 - val_loss: 0.9382 - val_accuracy: 0.6672\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 12s 779ms/step - loss: 0.9414 - accuracy: 0.6720 - val_loss: 0.9423 - val_accuracy: 0.6665\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x276e8c9eb90>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=256, epochs=10, validation_split=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpxPXbXphKid"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "JhWGlmnSu8Cm",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "outputId": "080e805e-6226-48a8-8ec3-7b50a20324df",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:36:10.524052900Z",
     "start_time": "2023-05-12T17:36:08.952221700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 21ms/step\n",
      "F1 score: 0.54\n",
      "Precision: 0.52\n",
      "Recall: 0.67\n",
      "Accuracy: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tobyj\\PycharmProjects\\COM3025-CW\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "output_metrics(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "YpiifHQ9u8Cm",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:36:10.566391Z",
     "start_time": "2023-05-12T17:36:10.525054900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame with 'lesion_id' and 'cell_type_dx' columns from the test data\n",
    "result_df = pd.DataFrame({'lesion_id': test_df['lesion_id'], 'target': y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JElKkmMj_8j"
   },
   "source": [
    "# Smoothgrad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ZJdjpwZOsCZp",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:36:10.589761300Z",
     "start_time": "2023-05-12T17:36:10.542935200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import PIL.Image\n",
    "from torchvision import models, transforms\n",
    "from matplotlib import pylab as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "wiuvG8mOsNqk",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:36:10.590685500Z",
     "start_time": "2023-05-12T17:36:10.555159400Z"
    }
   },
   "outputs": [],
   "source": [
    "class_idx_str = 'class_idx_str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "N0FkwjCJs8_n",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:36:10.590685500Z",
     "start_time": "2023-05-12T17:36:10.570881Z"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_OUTPUT_GRADIENTS = 'INPUT_OUTPUT_GRADIENTS'\n",
    "CONVOLUTION_LAYER_VALUES = 'CONVOLUTION_LAYER_VALUES'\n",
    "CONVOLUTION_OUTPUT_GRADIENTS = 'CONVOLUTION_OUTPUT_GRADIENTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Sa6perPzzK4E",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:36:10.662088300Z",
     "start_time": "2023-05-12T17:36:10.587164900Z"
    }
   },
   "outputs": [],
   "source": [
    "expected_keys = [INPUT_OUTPUT_GRADIENTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "xMKDQNRNsekV",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:36:10.663088300Z",
     "start_time": "2023-05-12T17:36:10.602716500Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_layer_outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "_XQ7SBxWqcSd",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:36:10.663088300Z",
     "start_time": "2023-05-12T17:36:10.617353300Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_model_function(images, call_model_args=None, expected_keys=None):\n",
    "    target_class_idx =  call_model_args[class_idx_str]\n",
    "    images = tf.convert_to_tensor(images)\n",
    "    with tf.GradientTape() as tape:\n",
    "        if expected_keys==[INPUT_OUTPUT_GRADIENTS]:\n",
    "            tape.watch(images)\n",
    "            _, output_layer = new_model(images)\n",
    "            output_layer = output_layer[:,target_class_idx]\n",
    "            gradients = np.array(tape.gradient(output_layer, images))\n",
    "            return {INPUT_OUTPUT_GRADIENTS: gradients}\n",
    "        else:\n",
    "            conv_layer, output_layer = new_model(images)\n",
    "            gradients = np.array(tape.gradient(output_layer, conv_layer))\n",
    "            return {CONVOLUTION_LAYER_VALUES: conv_layer,\n",
    "                    CONVOLUTION_OUTPUT_GRADIENTS: gradients}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "6mbaFPIGOiYU",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:36:10.663088300Z",
     "start_time": "2023-05-12T17:36:10.635065200Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_and_check_call_model_output(self, output, input_shape, expected_keys):\n",
    "  \"\"\"Converts keys in the output into an np.ndarray, and confirms its shape.\n",
    "\n",
    "  Args:\n",
    "    output: The output dictionary of data to be formatted.\n",
    "    input_shape: The shape of the input that yielded the output\n",
    "    expected_keys: List of keys inside output to format/check for shape agreement.\n",
    "\n",
    "  Raises:\n",
    "      ValueError: If output shapes do not match expected shape.\"\"\"\n",
    "  # If key is in check_full_shape, the shape should be equal to the input shape (e.g. \n",
    "  # INPUT_OUTPUT_GRADIENTS, which gives gradients for each value of the input). Otherwise,\n",
    "  # only checks the outermost dimension of output to match input_shape (i.e. the batch size\n",
    "  # should be the same).\n",
    "  check_full_shape = [INPUT_OUTPUT_GRADIENTS]\n",
    "  for expected_key in expected_keys:\n",
    "    output[expected_key] = np.asarray(output[expected_key])\n",
    "    expected_shape = input_shape\n",
    "    actual_shape = output[expected_key].shape\n",
    "    if expected_key not in check_full_shape:\n",
    "      expected_shape = expected_shape[0]\n",
    "      actual_shape = actual_shape[0]\n",
    "    if expected_shape != actual_shape:\n",
    "      raise ValueError(SHAPE_ERROR_MESSAGE[expected_key].format(\n",
    "                      expected_shape, actual_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "xzMDaanyQOa4",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:36:10.664132600Z",
     "start_time": "2023-05-12T17:36:10.656236200Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Utilities to compute SaliencyMasks.\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Output of the last convolution layer for the given input, including the batch\n",
    "# dimension.\n",
    "CONVOLUTION_LAYER_VALUES = 'CONVOLUTION_LAYER_VALUES'\n",
    "# Gradients of the output being explained (the logit/softmax value) with respect\n",
    "# to the last convolution layer, including the batch dimension.\n",
    "CONVOLUTION_OUTPUT_GRADIENTS = 'CONVOLUTION_OUTPUT_GRADIENTS'\n",
    "# Gradients of the output being explained (the logit/softmax value) with respect\n",
    "# to the input. Shape should be the same shape as x_value_batch.\n",
    "INPUT_OUTPUT_GRADIENTS = 'INPUT_OUTPUT_GRADIENTS'\n",
    "# Value of the output being explained (the logit/softmax value).\n",
    "OUTPUT_LAYER_VALUES = 'OUTPUT_LAYER_VALUES'\n",
    "\n",
    "SHAPE_ERROR_MESSAGE = {\n",
    "    CONVOLUTION_LAYER_VALUES: (\n",
    "        'Expected outermost dimension of CONVOLUTION_LAYER_VALUES to be the '\n",
    "        'same as x_value_batch - expected {}, actual {}'\n",
    "    ),\n",
    "    CONVOLUTION_OUTPUT_GRADIENTS: (\n",
    "        'Expected outermost dimension of CONVOLUTION_OUTPUT_GRADIENTS to be the '\n",
    "        'same as x_value_batch - expected {}, actual {}'\n",
    "    ),\n",
    "    INPUT_OUTPUT_GRADIENTS: (\n",
    "        'Expected key INPUT_OUTPUT_GRADIENTS to be the same shape as input '\n",
    "        'x_value_batch - expected {}, actual {}'\n",
    "    ),\n",
    "    OUTPUT_LAYER_VALUES: (\n",
    "        'Expected outermost dimension of OUTPUT_LAYER_VALUES to be the same as'\n",
    "        ' x_value_batch - expected {}, actual {}'\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "class CoreSaliency(object):\n",
    "  r\"\"\"Base class for saliency methods. Alone, this class doesn't do anything.\"\"\"\n",
    "\n",
    "  def GetMask(self, x_value, call_model_function, call_model_args=None):\n",
    "    \"\"\"Returns an unsmoothed mask.\n",
    "\n",
    "    Args:\n",
    "      x_value: Input ndarray.\n",
    "      call_model_function: A function that interfaces with a model to return\n",
    "        specific output in a dictionary when given an input and other arguments.\n",
    "        Expected function signature:\n",
    "        - call_model_function(x_value_batch,\n",
    "                              call_model_args=None,\n",
    "                              expected_keys=None):\n",
    "          x_value_batch - Input for the model, given as a batch (i.e. dimension\n",
    "            0 is the batch dimension, dimensions 1 through n represent a single\n",
    "            input).\n",
    "          call_model_args - Other arguments used to call and run the model.\n",
    "          expected_keys - List of keys that are expected in the output. Possible\n",
    "            keys in this list are CONVOLUTION_LAYER_VALUES, \n",
    "            CONVOLUTION_OUTPUT_GRADIENTS, INPUT_OUTPUT_GRADIENTS, and\n",
    "            OUTPUT_LAYER_VALUES, and are explained in detail where declared.\n",
    "      call_model_args: The arguments that will be passed to the call model\n",
    "        function, for every call of the model.\n",
    "\n",
    "    \"\"\"\n",
    "    raise NotImplementedError('A derived class should implemented GetMask()')\n",
    "\n",
    "  def GetSmoothedMask(self,\n",
    "                      x_value,\n",
    "                      call_model_function,\n",
    "                      call_model_args=None,\n",
    "                      stdev_spread=.15,\n",
    "                      nsamples=25,\n",
    "                      magnitude=True,\n",
    "                      **kwargs):\n",
    "    \"\"\"Returns a mask that is smoothed with the SmoothGrad method.\n",
    "\n",
    "    Args:\n",
    "      x_value: Input ndarray.\n",
    "      call_model_function: A function that interfaces with a model to return\n",
    "        specific output in a dictionary when given an input and other arguments.\n",
    "        Expected function signature:\n",
    "        - call_model_function(x_value_batch,\n",
    "                              call_model_args=None,\n",
    "                              expected_keys=None):\n",
    "          x_value_batch - Input for the model, given as a batch (i.e. dimension\n",
    "            0 is the batch dimension, dimensions 1 through n represent a single\n",
    "            input).\n",
    "          call_model_args - Other arguments used to call and run the model.\n",
    "          expected_keys - List of keys that are expected in the output. Possible\n",
    "            keys in this list are CONVOLUTION_LAYER_VALUES,\n",
    "            CONVOLUTION_OUTPUT_GRADIENTS, INPUT_OUTPUT_GRADIENTS, and\n",
    "            OUTPUT_LAYER_VALUES, and are explained in detail where declared.\n",
    "      call_model_args: The arguments that will be passed to the call model\n",
    "        function, for every call of the model.\n",
    "      stdev_spread: Amount of noise to add to the input, as fraction of the\n",
    "                    total spread (x_max - x_min). Defaults to 15%.\n",
    "      nsamples: Number of samples to average across to get the smooth gradient.\n",
    "      magnitude: If true, computes the sum of squares of gradients instead of\n",
    "                 just the sum. Defaults to true.\n",
    "    \"\"\"\n",
    "    stdev = stdev_spread * (np.max(x_value) - np.min(x_value))\n",
    "\n",
    "    total_gradients = np.zeros_like(x_value, dtype=np.float32)\n",
    "    for _ in range(nsamples):\n",
    "      noise = np.random.normal(0, stdev, x_value.shape)\n",
    "      x_plus_noise = x_value + noise\n",
    "      grad = self.GetMask(x_plus_noise, call_model_function, call_model_args,\n",
    "                          **kwargs)\n",
    "      if magnitude:\n",
    "        total_gradients += (grad * grad)\n",
    "      else:\n",
    "        total_gradients += grad\n",
    "\n",
    "    return total_gradients / nsamples\n",
    "\n",
    "  def format_and_check_call_model_output(self, output, input_shape, expected_keys):\n",
    "    \"\"\"Converts keys in the output into an np.ndarray, and confirms its shape.\n",
    "\n",
    "    Args:\n",
    "      output: The output dictionary of data to be formatted.\n",
    "      input_shape: The shape of the input that yielded the output\n",
    "      expected_keys: List of keys inside output to format/check for shape agreement.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If output shapes do not match expected shape.\"\"\"\n",
    "    # If key is in check_full_shape, the shape should be equal to the input shape (e.g. \n",
    "    # INPUT_OUTPUT_GRADIENTS, which gives gradients for each value of the input). Otherwise,\n",
    "    # only checks the outermost dimension of output to match input_shape (i.e. the batch size\n",
    "    # should be the same).\n",
    "    check_full_shape = [INPUT_OUTPUT_GRADIENTS]\n",
    "    for expected_key in expected_keys:\n",
    "      output[expected_key] = np.asarray(output[expected_key])\n",
    "      expected_shape = input_shape\n",
    "      actual_shape = output[expected_key].shape\n",
    "      if expected_key not in check_full_shape:\n",
    "        expected_shape = expected_shape[0]\n",
    "        actual_shape = actual_shape[0]\n",
    "      if expected_shape != actual_shape:\n",
    "        raise ValueError(SHAPE_ERROR_MESSAGE[expected_key].format(\n",
    "                       expected_shape, actual_shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "vMYQuC0onOFp",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:36:10.683964400Z",
     "start_time": "2023-05-12T17:36:10.665088Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Utilities to compute saliency by returning the output gradients.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class GradientSaliency(CoreSaliency):\n",
    "  \"\"\"A CoreSaliency class that computes saliency masks with gradients.\"\"\"\n",
    "\n",
    "  expected_keys = [INPUT_OUTPUT_GRADIENTS]\n",
    "\n",
    "  def GetMask(self, x_value, call_model_function, call_model_args=None):\n",
    "    \"\"\"Returns a vanilla gradients mask.\n",
    "\n",
    "    Args:\n",
    "      x_value: Input ndarray.\n",
    "      call_model_function: A function that interfaces with a model to return\n",
    "        specific data in a dictionary when given an input and other arguments.\n",
    "        Expected function signature:\n",
    "        - call_model_function(x_value_batch,\n",
    "                              call_model_args=None,\n",
    "                              expected_keys=None):\n",
    "          x_value_batch - Input for the model, given as a batch (i.e. dimension\n",
    "            0 is the batch dimension, dimensions 1 through n represent a single\n",
    "            input).\n",
    "          call_model_args - Other arguments used to call and run the model.\n",
    "          expected_keys - List of keys that are expected in the output. For this\n",
    "            method (Gradients), the expected keys are\n",
    "            INPUT_OUTPUT_GRADIENTS - Gradients of the output layer\n",
    "              (logit/softmax) with respect to the input. Shape should be the\n",
    "              same shape as x_value_batch.\n",
    "      call_model_args: The arguments that will be passed to the call model\n",
    "        function, for every call of the model.\n",
    "    \"\"\"\n",
    "    x_value_batched = np.expand_dims(x_value, axis=0)\n",
    "    call_model_output = call_model_function(\n",
    "        x_value_batched,\n",
    "        call_model_args=call_model_args,\n",
    "        expected_keys=self.expected_keys)\n",
    "\n",
    "    self.format_and_check_call_model_output(call_model_output,\n",
    "                                            x_value_batched.shape,\n",
    "                                            self.expected_keys)\n",
    "\n",
    "    return call_model_output[INPUT_OUTPUT_GRADIENTS][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Application"
   ],
   "metadata": {
    "id": "nXV_484h8qBm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "heatmap_images = []\n",
    "raw_gradients = []"
   ],
   "metadata": {
    "id": "SazY4Jp63LlD",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:47:22.067644600Z",
     "start_time": "2023-05-12T17:47:22.047871200Z"
    }
   },
   "execution_count": 125,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "last_conv_layer = model.get_layer(index=-3)\n",
    "new_model = tf.keras.models.Model(inputs=model.input, \n",
    "                                   outputs=[last_conv_layer.output, model.output])"
   ],
   "metadata": {
    "id": "hggXkmPO3DYK",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:47:22.273049500Z",
     "start_time": "2023-05-12T17:47:22.221341200Z"
    }
   },
   "execution_count": 126,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "smoothgrad = GradientSaliency()"
   ],
   "metadata": {
    "id": "_nfiPssg9rfe",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:47:22.413143100Z",
     "start_time": "2023-05-12T17:47:22.401592600Z"
    }
   },
   "execution_count": 127,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "images = df['path']"
   ],
   "metadata": {
    "id": "XWJbnZ2dKKQP",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:47:22.601895Z",
     "start_time": "2023-05-12T17:47:22.590330500Z"
    }
   },
   "execution_count": 128,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from PIL import Image"
   ],
   "metadata": {
    "id": "CkRYNrV5Oath",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:47:22.756011300Z",
     "start_time": "2023-05-12T17:47:22.745425200Z"
    }
   },
   "execution_count": 129,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:47:24.404748800Z",
     "start_time": "2023-05-12T17:47:22.913878600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "images = df['path']\n",
    "baseline = np.zeros(image_size)\n",
    "prediction_class = np.argmax(predictions[0])\n",
    "call_model_args = {class_idx_str: prediction_class}\n",
    "gradient_saliency = GradientSaliency()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:47:24.446910400Z",
     "start_time": "2023-05-12T17:47:24.281682200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for img in images[:100]:\n",
    "  img_arr = read_and_resize_image(image_path=img, size=image_size)\n",
    "  im_tensor = PreprocessImages([img_arr])\n",
    "  im = img_arr.astype(np.float32)\n",
    "  smoothgrad = GradientSaliency()\n",
    "  vanilla_integrated_gradients_mask_3d = smoothgrad.GetSmoothedMask(\n",
    "    im, call_model_function, call_model_args)\n",
    "  raw_gradients.append(vanilla_integrated_gradients_mask_3d)\n",
    "  heatmap_images.append(visualiseImageToHeatmap(vanilla_integrated_gradients_mask_3d))"
   ],
   "metadata": {
    "id": "fe1WZKB92AuA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f07c0b01-a900-44a8-e5da-059633c69b43",
    "ExecuteTime": {
     "end_time": "2023-05-12T17:48:13.261057200Z",
     "start_time": "2023-05-12T17:47:24.305728600Z"
    }
   },
   "execution_count": 132,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "def convert_to_boolean_mask(image):\n",
    "    # Convert the image to a NumPy array\n",
    "    image = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Create a boolean mask where white pixels are True and black pixels are False\n",
    "    binary_image = np.where(image == 255, True, False)  # Assuming white pixels are represented as 255\n",
    "\n",
    "    cropped_image = cv2.resize(binary_image.astype(np.uint8), (64, 64))\n",
    "\n",
    "    return cropped_image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:48:13.272572500Z",
     "start_time": "2023-05-12T17:48:13.263021500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path):\n",
    "    image_paths = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            image_paths.append(img_path)\n",
    "    return image_paths"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:48:13.323361Z",
     "start_time": "2023-05-12T17:48:13.274569800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "folder_path = 'content/HAM10000_segmentations_lesion_tschandl/HAM10000_segmentations_lesion_tschandl'\n",
    "image_list = load_images_from_folder(folder_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:48:13.784013500Z",
     "start_time": "2023-05-12T17:48:13.291783600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "segment_images = load_images_from_folder(folder_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:48:14.265928600Z",
     "start_time": "2023-05-12T17:48:13.786014800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "boolean_masks = []\n",
    "for img in image_list:\n",
    "    boolean_masks.append(convert_to_boolean_mask(img))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:48:25.910990900Z",
     "start_time": "2023-05-12T17:48:14.267437100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(boolean_masks[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:48:25.924508800Z",
     "start_time": "2023-05-12T17:48:25.911986400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "10015\n",
      "10015\n"
     ]
    }
   ],
   "source": [
    "print(len(heatmap_images))\n",
    "print(len(raw_gradients))\n",
    "print(len(boolean_masks))\n",
    "print(len(segment_images))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:48:26.015776300Z",
     "start_time": "2023-05-12T17:48:25.928605400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "def calculate_overlap(g, m) -> float:\n",
    "    # Invert the mask, so the pixels outside are True.\n",
    "    m[:] = ~m\n",
    "    # Replace where the mask is False, with a 0 in the same location in raw_gradients\n",
    "    segment = np.where(np.array(m), np.array(g), 0)\n",
    "    # We now have just the gradients in a 2D vector of the pixels outside the bounding box\n",
    "    sum_mask_segment = np.sum(segment)\n",
    "    # Find what percentage the outside pixels make up of the full gradient image by summing both 2D vectors\n",
    "    total_sum = np.sum(g)\n",
    "    # What percentage are the gradients outside the segment of the full gradient vector\n",
    "    overlap = (sum_mask_segment / total_sum) * 100\n",
    "\n",
    "    return overlap"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:48:26.016752100Z",
     "start_time": "2023-05-12T17:48:25.945123700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "overlap = []\n",
    "for i in range(len(raw_gradients)):\n",
    "    overlap.append(calculate_overlap(raw_gradients[i][:, :, 0], boolean_masks[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:48:42.096349200Z",
     "start_time": "2023-05-12T17:48:42.053611500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64.69895839691162, 69.25045847892761, 64.79473114013672, 62.60273456573486, 53.59896421432495, 46.980392932891846, 66.85472130775452, 32.4913889169693, 37.30055391788483, 34.83521640300751, 74.01122450828552, 74.18679594993591, 58.25604200363159, 54.74798083305359, 69.47416663169861, 41.07440114021301, 50.38600564002991, 65.8160924911499, 37.44594752788544, 68.15176606178284, 13.18306028842926, 65.1157021522522, 78.46794128417969, 38.24547231197357, 57.59795308113098, 60.185396671295166, 70.64076662063599, 68.64267587661743, 64.36299681663513, 23.70997965335846, 49.1234689950943, 49.740320444107056, 67.10292100906372, 39.939820766448975, 38.432008028030396, 57.26420879364014, 36.790502071380615, 73.26548099517822, 31.174948811531067, 71.92437052726746, 29.7198086977005, 44.85253095626831, 60.66780686378479, 77.81733274459839, 29.9159437417984, 82.13866949081421, 39.464545249938965, 43.214982748031616, 65.87246656417847, 45.669737458229065, 60.768431425094604, 70.64183950424194, 47.66165614128113, 70.64818143844604, 34.391334652900696, 81.76110982894897, 64.96102809906006, 24.661409854888916, 34.552404284477234, 83.92901420593262, 36.10738813877106, 30.944693088531494, 27.415364980697632, 59.91827845573425, 58.6037278175354, 81.95202946662903, 69.87202763557434, 45.97121477127075, 69.68545913696289, 3.221730515360832, 48.52960407733917, 27.387341856956482, 3.2219894230365753, 52.994102239608765, 42.50858724117279, 93.93171668052673, 70.94582915306091, 68.17887425422668, 27.77988910675049, 8.313468098640442, 35.85205078125, 16.488949954509735, 84.19865369796753, 18.752506375312805, 75.26951432228088, 9.38645824790001, 73.0671763420105, 30.90338110923767, 75.67610740661621, 80.61725497245789, 20.54501175880432, 73.96080493927002, 32.57421851158142, 45.47019004821777, 89.4317090511322, 50.944751501083374, 19.278423488140106, 42.14174747467041, 11.253252625465393, 53.25477719306946]\n"
     ]
    }
   ],
   "source": [
    "print(overlap)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T17:48:42.592599600Z",
     "start_time": "2023-05-12T17:48:42.538405700Z"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "gpuType": "T4",
   "collapsed_sections": [
    "CgNdhpLOvFjm",
    "Q7A6B6RebmmE",
    "FpxPXbXphKid"
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
